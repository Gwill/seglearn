{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Simple imbalanced-learn example\n\nThis example demonstrates how to use imbalanced-learn resample transforms inside a seglearn Pype.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Matthias Gazzari\n# License: BSD\n\nimport numpy as np\n\nfrom sklearn.dummy import DummyClassifier\n\nfrom seglearn.pipe import Pype\nfrom seglearn.transform import Segment, patch_sampler, FeatureRep\nfrom seglearn.feature_functions import minimum\nfrom seglearn.split import temporal_split\n\n\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Single univariate time series with 10 samples\nX = [np.array([[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5,6], [6, 7], [7, 8], [8, 9], [9, 10]])]\n# Time series target (imbalanced towards False)\ny = [np.array([True, False, False, False, False, False, True, False, False, False])]\n\nprint(\"Implementation details: transform and fit_transform methods:\")\n\npipe = Pype([\n    ('segment', Segment(width=1, overlap=0)),\n    ('resample', patch_sampler(RandomUnderSampler)()),\n])\nprint(\"Pipeline:\", pipe)\n\nprint(\"Calling a transform on the data does not change it ...\")\nXf, yf = pipe.transform(X, y)\nprint(\"X (flattened):\", Xf.flatten())\nprint(\"y\", yf)\n\nprint(\"... but calling fit_transform resamples the data.\")\nXf, yf = pipe.fit_transform(X, y)\nprint(\"X (flattened):\", Xf.flatten())\nprint(\"y\", yf)\n\nprint()\nprint(\"VerboseDummyClassifier example:\")\nprint()\n\nclass VerboseDummyClassifier(DummyClassifier):\n    def fit(self, X, y, sample_weight=None):\n        print(\"Fitting X (flattened):\", X.flatten(), \"on y:\", y)\n        return super(VerboseDummyClassifier, self).fit(X, y, sample_weight)\n    def predict(self, X):\n        print(\"Predicting X (flattened):\", X.flatten())\n        return super(VerboseDummyClassifier, self).predict(X)\n    def score(self, X, y, sample_weight=None):\n        print(\"Scoring X (flattened):\", X.flatten(), \"on y:\", y)\n        return super(VerboseDummyClassifier, self).score(X, y, sample_weight)\n\npipe = Pype([\n    ('segment', Segment(width=1, overlap=0)),\n    ('resample', patch_sampler(RandomUnderSampler)(shuffle=True)),\n    ('feature', FeatureRep(features={\"min\":minimum})),\n    ('estimator', VerboseDummyClassifier(strategy=\"constant\", constant=True)),\n])\nprint(\"Pipeline:\", pipe)\n\nprint(\"Split the data into half training and half test data:\")\nX_train, X_test, y_train, y_test = temporal_split(X, y, 0.5)\nprint(\"X_train:\", X_train)\nprint(\"y_train:\", y_train)\nprint(\"X_test:\", X_test)\nprint(\"y_test:\", y_test)\nprint()\n\nprint(\"Fit on the training data (this includes resampling):\")\npipe.fit(X_train, y_train)\nprint()\n\nprint(\"Score the fitted estimator on test data (this excludes resampling):\")\nscore = pipe.score(X_test, y_test)\nprint(\"Score: \", score)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}